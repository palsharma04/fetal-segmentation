# -*- coding: utf-8 -*-
"""Copy of MONAI_testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-VfqNfU8ixBdzttR_YlZCaDPEXhm8412

# Testing
"""

import glob
from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd, ScaleIntensityRanged, CropForegroundd, ToTensord
from monai.data import CacheDataset, DataLoader
from monai.transforms import ScaleIntensityd

# Step 1: Load test files
test_images = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/imagesTs/*.nii.gz"))
test_labels = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/labelsTs/*.nii.gz"))
test_files = [{"image": img, "label": lbl} for img, lbl in zip(test_images, test_labels)]

target_size = [128, 128, 128]
# Step 2: Define transforms
test_transforms = Compose([
    LoadImaged(keys=["image", "label"]),
    EnsureChannelFirstd(keys=["image", "label"]),
    Spacingd(keys=["image", "label"], pixdim=(0.8, 0.8, 4.0), mode=("bilinear", "nearest")),
    SpatialPadd(keys=["image", "label"], spatial_size=target_size, method="symmetric"),
    Resized(keys=["image", "label"], spatial_size=target_size, mode=("trilinear", "nearest")),
    ScaleIntensityd(keys=["image"]),
    ToTensord(keys=["image", "label"]),
])

# Step 3: Create dataset and loader
test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_num=6, cache_rate=1.0, num_workers=4)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)

print(f"Test set ready: {len(test_loader)} samples")

import os
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric
from monai.transforms import AsDiscrete, Compose
from monai.networks.utils import one_hot

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Step 1: Load model
model = UNet(
    spatial_dims=3,
    in_channels=1,
    out_channels=6,
    channels=(32, 64, 128, 256, 512),
    strides=(2, 2, 2, 2),
    kernel_size=3,
    up_kernel_size=3,
    num_res_units=1,
    act='PRELU',
    norm='INSTANCE',
    dropout=0.5
).to(device)

data_dir = '/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/'
model.load_state_dict(torch.load(os.path.join(data_dir, "best_metric_model.pth")))
model.eval()

# --- Step 2: DiceMetric
dice_metric = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)
# Re-create dice_metric fresh
dice_metric_case = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)

# --- Step 3: Inference
all_preds = []
all_labels = []
case_dice_scores = []

num_classes = 6
roi_size = (128, 128, 128)

with torch.no_grad():
    for batch in tqdm(test_loader):
        test_images, test_labels = batch["image"].to(device), batch["label"].to(device)
        test_outputs = sliding_window_inference(test_images, roi_size=roi_size, sw_batch_size=1, predictor=model)

        test_outputs = torch.argmax(test_outputs, dim=1).unsqueeze(1)  # (B, 1, H, W, D)
        test_outputs = one_hot(test_outputs, num_classes=num_classes)

        if test_labels.ndim == 4:
            test_labels = test_labels.unsqueeze(1)
        test_labels = one_hot(test_labels, num_classes=num_classes)

        dice_metric_case.reset()
        dice_metric(y_pred=test_outputs, y=test_labels)
        dice_metric_case(y_pred=test_outputs, y=test_labels)
        case_dice = dice_metric_case.aggregate().item()

        case_dice_scores.append(case_dice)

        all_preds.append(test_outputs.cpu())
        all_labels.append(test_labels.cpu())

# --- Step 4: Calculate mean Dice
mean_dice = dice_metric.aggregate().item()
per_class_dice = dice_metric.aggregate(reduction=None).cpu().numpy()  # Get per-class Dice

print(f"Mean Dice on Test Set: {mean_dice:.4f}")
print("Dice per label (excluding background):")
for i, dice_val in enumerate(per_class_dice):
    print(f"Label {i+1}: {dice_val:.4f}")  # i+1 because label 0 is skipped

dice_metric.reset()

# --- Step 5: Volume Calculation
y_pred = torch.cat(all_preds, dim=0)
y = torch.cat(all_labels, dim=0)

spacing = [0.8, 0.8, 4.0]  # mm
voxel_volume_mm3 = np.prod(spacing)

labels = [0, 1, 2, 3, 4, 5]
volume_differences = []

for i in range(len(y_pred)):
    pred = y_pred[i].argmax(0).numpy()  # convert from one-hot
    gt = y[i].argmax(0).numpy()

    case_diff = {}
    for label in labels:
        pred_voxels = np.sum(pred == label)
        gt_voxels = np.sum(gt == label)

        pred_volume = pred_voxels * voxel_volume_mm3
        gt_volume = gt_voxels * voxel_volume_mm3
        volume_difference = pred_volume - gt_volume

        if gt_volume > 0:
            volume_error_percent = (volume_difference / gt_volume) * 100
        else:
            volume_error_percent = np.nan

        case_diff[f"Label_{label}_GT_volume_mm3"] = gt_volume
        case_diff[f"Label_{label}_Pred_volume_mm3"] = pred_volume
        case_diff[f"Label_{label}_Diff_volume_mm3"] = volume_difference
        case_diff[f"Label_{label}_Error_percent"] = volume_error_percent

    volume_differences.append(case_diff)

# --- Step 6: Dice, Precision, Recall, Volume Differences (cc and %)
case_ids = [os.path.basename(f["image"]) for f in test_ds.data]
combined_results = []

for i, case_id in enumerate(case_ids):
    row = {"Case": case_id}

    pred = y_pred[i].argmax(0).numpy()
    gt = y[i].argmax(0).numpy()

    def calc_metrics(pred_mask, gt_mask):
        tp = np.logical_and(pred_mask, gt_mask).sum()
        fp = np.logical_and(pred_mask, np.logical_not(gt_mask)).sum()
        fn = np.logical_and(np.logical_not(pred_mask), gt_mask).sum()

        dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 1.0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 1.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 1.0

        pred_vol_cc = pred_mask.sum() * voxel_volume_mm3 / 1000  # in cc
        gt_vol_cc = gt_mask.sum() * voxel_volume_mm3 / 1000
        abs_diff = pred_vol_cc - gt_vol_cc
        rel_diff = (abs_diff / gt_vol_cc) * 100 if gt_vol_cc > 0 else np.nan

        return round(dice, 4), round(precision, 4), round(recall, 4), round(abs_diff, 2), round(rel_diff, 2)

    label_groups = {
        "fetus": [1, 5],
        "placenta": [2],
        "umbilical_cord": [3],
        "amniotic_fluid": [4]
    }

    for name, indices in label_groups.items():
        pred_mask = np.isin(pred, indices)
        gt_mask = np.isin(gt, indices)

        dice, precision, recall, abs_vol_diff_cc, rel_vol_diff_pct = calc_metrics(pred_mask, gt_mask)

        row[f"{name}_dice"] = dice
        row[f"{name}_precision"] = precision
        row[f"{name}_recall"] = recall
        row[f"{name}_abs_vol_diff_cc"] = abs_vol_diff_cc
        row[f"{name}_rel_vol_diff_percent"] = rel_vol_diff_pct

    combined_results.append(row)

# --- Save full results to CSV
df_combined = pd.DataFrame(combined_results)
save_path = os.path.join(data_dir, "testing_plots", "3d-all_metrics_per_case.csv")
df_combined.to_csv(save_path, index=False)

print(f"All metrics saved to: {save_path}")
df_combined.head()

"""Visualising Test Sample"""

import matplotlib.pyplot as plt
import numpy as np

# Pick a test sample
sample_idx = 0  # change this to see different samples

# Load the sample
test_data = test_ds[sample_idx]
test_image = test_data["image"][0].numpy()  # (1, H, W, D) -> [H, W, D]
test_label = test_data["label"][0].numpy()  # (1, H, W, D)

# Predict
model.eval()
with torch.no_grad():
    input_tensor = test_data["image"].unsqueeze(0).to(device)  # Add batch dimension
    pred = sliding_window_inference(input_tensor, roi_size=(128,128,128), sw_batch_size=1, predictor=model)
    pred = torch.argmax(pred, dim=1).cpu().numpy()[0]  # (B, H, W, D) -> (H, W, D)

# Pick a slice to visualize
slice_idx = test_image.shape[2] // 2  # middle slice

fig, axs = plt.subplots(1, 3, figsize=(18, 6))

axs[0].imshow(test_image[:,:,slice_idx], cmap="gray")
axs[0].set_title("Input Image")

axs[1].imshow(test_label[:,:,slice_idx])
axs[1].set_title("Ground Truth Label")

axs[2].imshow(pred[:,:,slice_idx])
axs[2].set_title("Predicted Label")

plt.show()

case_num = 1
img_dim = 128
class_n = 6
qq=round(img_dim/2)
alpha_val = 0.6
with torch.no_grad():
    img_name = test_files[case_num]["image"]
    cur_case = test_ds[case_num]
    img = cur_case["image"]
    label = cur_case["label"]
    val_inputs = torch.unsqueeze(img, 1).cuda()
    val_labels = torch.unsqueeze(label, 1).cuda()
    val_outputs = sliding_window_inference(
        val_inputs, (img_dim, img_dim, img_dim), 4, model, overlap=0.8
    )
    plt.figure("check", (18, 18))
    plt.subplot(3, 3, 1)
    plt.title("Input image")
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, qq], cmap="gray")
    plt.subplot(3, 3, 2)
    plt.title("GT label")
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, qq], cmap="gray")
    plt.imshow(val_labels.cpu().numpy()[0, 0, :, :, qq], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")
    plt.subplot(3, 3, 3)
    plt.title("CNN output")
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, qq], cmap="gray")
    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, qq], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")

    plt.subplot(3, 3, 4)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, qq, :], cmap="gray")
    plt.subplot(3, 3, 5)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, qq, :], cmap="gray")
    plt.imshow(val_labels.cpu().numpy()[0, 0, :, qq, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")
    plt.subplot(3, 3, 6)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, qq, :], cmap="gray")
    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, qq, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")


    plt.subplot(3, 3, 7)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, qq, :, :], cmap="gray")
    plt.subplot(3, 3, 8)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, qq, :, :], cmap="gray")
    plt.imshow(val_labels.cpu().numpy()[0, 0, qq, :, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")
    plt.subplot(3, 3, 9)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, qq, :, :], cmap="gray")
    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, qq, :, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")

    plt.show()

"""# **2D MONAI**"""

from monai.transforms import Lambdad

def combine_fetus_labels(label):
    label = label.clone()
    label[label == 5] = 1
    return label

from monai.utils import first

# Step 1: Load test files
test_images = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/imagesTs/*.nii.gz"))
test_labels = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/labelsTs/*.nii.gz"))
test_files = []
for img, lbl in zip(test_images, test_labels):
    case_name = os.path.basename(img).split(".")[0]
    test_files.append({"image": img, "label": lbl, "case_name": case_name})

degree_min = -2.05
degree_max = 2.05
target_size = [128, 128, 128]
# Step 2: Define transforms
test_transforms = Compose([
    LoadImaged(keys=["image", "label"]),
    EnsureChannelFirstd(keys=["image", "label"]),
    Lambdad(keys="label", func=combine_fetus_labels),
    Spacingd(keys=["image", "label"], pixdim=(0.8, 0.8, 4.0), mode=("bilinear", "nearest")),
    SpatialPadd(keys=["image", "label"], spatial_size=target_size, method="symmetric"),
    Resized(keys=["image", "label"], spatial_size=target_size, mode=("trilinear", "nearest")),
    ScaleIntensityRanged(keys=["image"], a_min=0, a_max=1002, b_min=0.0, b_max=1.0, clip=True),
    ToTensord(keys=["image", "label"]),
])

# Step 3: Create dataset and loader
test_volume_ds = CacheDataset(data=test_files, transform=test_transforms)
test_check_loader = DataLoader(test_volume_ds, batch_size=1)
test_check_data = first(test_check_loader)
print("first volume's shape: ", test_check_data["image"].shape, test_check_data["label"].shape)

print(f"Test set ready: {len(test_check_loader)} samples")

from monai.data import PatchIterd, GridPatchDataset
from monai.transforms import SqueezeDimd

patch_func = PatchIterd(
    keys=["image", "label"],
    patch_size=(128, 128, 1),  # dynamic first two dimensions
    start_pos=(0, 0, 0)
)
patch_transform = Compose(
    [
        SqueezeDimd(keys=["image", "label"], dim=-1),  # squeeze the last dim
        Resized(keys=["image", "label"], spatial_size=[128, 128]),
    ]
)

test_patch_ds = GridPatchDataset(
    data=test_volume_ds, patch_iter=patch_func, transform=patch_transform, with_coordinates=False)
test_loader = DataLoader(
    test_patch_ds,
    batch_size=5,
    num_workers=0,
    pin_memory=torch.cuda.is_available(),
)
test_check_data = first(test_loader)

import torch
from collections import defaultdict

# After loading test file paths:
test_images = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/imagesTs/*.nii.gz"))
test_labels = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/labelsTs/*.nii.gz"))

case_names = [os.path.basename(img).split(".")[0] for img in test_images]

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = UNet(
    spatial_dims=2,
    in_channels=1,
    out_channels=5,
    channels=(32, 64, 128, 256, 512),
    strides=(2,2,2,2),
    kernel_size=3,
    up_kernel_size=3,
    num_res_units=1,
    act='PRELU',
    norm='INSTANCE',
    dropout=0.5
).to(device)

data_dir = '/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/'
model.load_state_dict(torch.load(os.path.join(data_dir, "2d_best_metric_model.pth")))
model.eval()

# --- Step 2: Metrics
dice_metric = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)
dice_metric_case = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)
slice_dice_per_case = defaultdict(list)

# --- Step 3: Inference
all_preds = []
all_labels = []
case_dice_scores = []
all_case_names = []

num_classes = 5
roi_size = (128, 128)

with torch.no_grad():
    for batch in tqdm(test_loader):
        image = batch["image"].to(device)
        label = batch["label"].to(device)

        case_name = batch["case_name"][0]
        all_case_names.append(case_name)

        test_outputs = model(image)
        test_outputs = torch.argmax(test_outputs, dim=1).unsqueeze(1)
        test_outputs = one_hot(test_outputs, num_classes=num_classes)

        if label.ndim == 3:
            label = label.unsqueeze(1)
        label = one_hot(label, num_classes=num_classes)

        # Optional: track dice per slice
        dice_metric_case.reset()
        dice_metric_case(y_pred=test_outputs, y=label)
        slice_dice = dice_metric_case.aggregate().item()
        slice_dice_per_case[case_name].append(slice_dice)

        all_preds.append(test_outputs.cpu())
        all_labels.append(label.cpu())

# After inference: Average slices per case
case_dice_scores = []
final_case_names = []

for case, slice_scores in slice_dice_per_case.items():
    avg_case_dice = sum(slice_scores) / len(slice_scores)
    case_dice_scores.append(avg_case_dice)
    final_case_names.append(case)

import numpy as np
import pandas as pd

voxel_spacing_mm = [0.8, 0.8, 4.0]  # Adjust if needed
voxel_volume_mm3 = np.prod(voxel_spacing_mm)
voxel_volume_cc = voxel_volume_mm3 / 1000

label_names = {
    1: "fetus",
    2: "placenta",
    3: "umbilical_cord",
    4: "amniotic_fluid"
}

# Dict to store per-slice metrics by case
metrics_by_case = defaultdict(lambda: defaultdict(list))

for i in range(len(all_preds)):
    pred = all_preds[i].argmax(dim=1).squeeze().numpy()  # (slices, H, W)
    gt = all_labels[i].argmax(dim=1).squeeze().numpy()

    current_case = all_case_names[i]

    gt[gt == 5] = 1

    for label, name in label_names.items():
        pred_mask = (pred == label)
        gt_mask = (gt == label)

        tp = np.logical_and(pred_mask, gt_mask).sum()
        fp = np.logical_and(pred_mask, ~gt_mask).sum()
        fn = np.logical_and(~pred_mask, gt_mask).sum()

        dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 1.0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 1.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 1.0

        pred_vol_cc = pred_mask.sum() * voxel_volume_cc
        gt_vol_cc = gt_mask.sum() * voxel_volume_cc
        abs_diff = pred_vol_cc - gt_vol_cc
        rel_diff = (abs_diff / gt_vol_cc) * 100 if gt_vol_cc > 0 else np.nan

        metrics_by_case[current_case][f"{name}_dice"].append(dice)
        metrics_by_case[current_case][f"{name}_precision"].append(precision)
        metrics_by_case[current_case][f"{name}_recall"].append(recall)
        metrics_by_case[current_case][f"{name}_abs_vol_diff_cc"].append(abs_diff)
        metrics_by_case[current_case][f"{name}_rel_vol_diff_percent"].append(rel_diff)

# --- Average metrics per case
final_results = []
for case, metrics in metrics_by_case.items():
    row = {"Case": case}
    for metric_name, values in metrics.items():
        values = [v for v in values if not np.isnan(v)]
        row[metric_name] = round(np.mean(values), 4) if values else np.nan
    final_results.append(row)

# --- Save CSV
df_final = pd.DataFrame(final_results)
save_path = os.path.join(data_dir, "testing_plots", "2d-all_metrics_per_case.csv")
df_final.to_csv(save_path, index=False)

print(f"Averaged slice-wise metrics saved to: {save_path}")
df_final.head()

from collections import defaultdict
import numpy as np
import os
import pandas as pd

voxel_volume_cc = np.prod([0.8, 0.8, 4.0]) / 1000  # update if spacing differs

label_names = {1: "fetus", 2: "placenta", 3: "umbilical_cord", 4: "amniotic_fluid"}

# gather per-slice metrics and voxel counts
case_stats = defaultdict(lambda: defaultdict(list))
case_vox   = defaultdict(lambda: defaultdict(lambda: {'pred':0, 'gt':0}))

for i in range(len(all_preds)):
    pred = all_preds[i].argmax(dim=1).squeeze().numpy()
    gt   = all_labels[i].argmax(dim=1).squeeze().numpy()
    gt[gt == 5] = 1                          # merge head & body
    case_id = all_case_names[i]

    for lab, name in label_names.items():
        pm = pred == lab
        gm = gt   == lab

        tp = np.logical_and(pm, gm).sum()
        fp = np.logical_and(pm, ~gm).sum()
        fn = np.logical_and(~pm, gm).sum()

        #pixel-wise metrics, keep slice averages
        dice      = 2*tp/(2*tp+fp+fn) if (2*tp+fp+fn) else 1.0
        precision = tp/(tp+fp)        if (tp+fp)        else 1.0
        recall    = tp/(tp+fn)        if (tp+fn)        else 1.0

        case_stats[case_id][f"{name}_dice"     ].append(dice)
        case_stats[case_id][f"{name}_precision"].append(precision)
        case_stats[case_id][f"{name}_recall"   ].append(recall)

        # voxel tallies for volume stats
        case_vox[case_id][name]['pred'] += pm.sum()
        case_vox[case_id][name]['gt'  ] += gm.sum()

# aggregate to case level
rows = []
for case_id, slice_metrics in case_stats.items():
    row = {'Case': case_id}

    # pixel-wise metrics → slice mean
    for m, vals in slice_metrics.items():
        row[m] = round(float(np.mean(vals)), 4)

    # volume metrics → compute once per case
    for name in label_names.values():
        gt_vox   = case_vox[case_id][name]['gt']
        pred_vox = case_vox[case_id][name]['pred']
        gt_vol   = gt_vox   * voxel_volume_cc
        pred_vol = pred_vox * voxel_volume_cc
        abs_diff = pred_vol - gt_vol
        rel_diff = (abs_diff / gt_vol * 100) if gt_vol else np.nan

        row[f"{name}_gt_volume_cc"        ] = round(gt_vol,   2)
        row[f"{name}_pred_volume_cc"      ] = round(pred_vol, 2)
        row[f"{name}_abs_vol_diff_cc"     ] = round(abs_diff, 2)
        row[f"{name}_rel_vol_diff_percent"] = round(rel_diff, 2)

    rows.append(row)

df_final = pd.DataFrame(rows)
out_csv  = os.path.join(data_dir, "testing_plots", "2d-all_metrics_per_case.csv")
df_final.to_csv(out_csv, index=False)
print("Saved:", out_csv)