import os
import numpy as np
import torch
from monai.transforms import (
    Compose, LoadImaged, AddChanneld, Spacingd, Orientationd,
    ScaleIntensityRanged, CropForegroundd, ToTensord
)
from monai.data import Dataset, DataLoader, CacheDataset
from monai.networks.nets import UNet
from monai.losses import DiceLoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference
from tqdm import tqdm

def get_transforms():
    return Compose([
        LoadImaged(keys=["image", "label"]),
        AddChanneld(keys=["image", "label"]),
        Spacingd(keys=["image", "label"], pixdim=(1.5, 1.5), mode=("bilinear", "nearest")),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        ScaleIntensityRanged(
            keys=["image"], a_min=-57, a_max=164,
            b_min=0.0, b_max=1.0, clip=True
        ),
        CropForegroundd(keys=["image", "label"], source_key="image"),
        ToTensord(keys=["image", "label"]),
    ])

def train():
    # Load data (adapt this part to your dataset structure)
    train_files = [{"image": "path/to/image1.nii.gz", "label": "path/to/label1.nii.gz"}, ...]
    val_files = [{"image": "path/to/image2.nii.gz", "label": "path/to/label2.nii.gz"}, ...]

    train_ds = CacheDataset(data=train_files, transform=get_transforms(), cache_rate=1.0)
    val_ds = CacheDataset(data=val_files, transform=get_transforms(), cache_rate=1.0)

    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=1)

    model = UNet(
        spatial_dims=2,
        in_channels=1,
        out_channels=4,  # adjust to number of labels
        channels=(16, 32, 64, 128, 256),
        strides=(2, 2, 2, 2),
        num_res_units=2
    ).to("cuda" if torch.cuda.is_available() else "cpu")

    loss_fn = DiceLoss(to_onehot_y=True, softmax=True)
    optimizer = torch.optim.Adam(model.parameters(), 1e-4)
    dice_metric = DiceMetric(include_background=False, reduction="mean", get_not_nans=True)

    for epoch in range(10):
        model.train()
        epoch_loss = 0
        for batch_data in tqdm(train_loader):
            inputs, labels = batch_data["image"].cuda(), batch_data["label"].cuda()
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        print(f"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}")

        # Evaluate
        model.eval()
        with torch.no_grad():
            dice_metric.reset()
            for val_data in val_loader:
                val_inputs, val_labels = val_data["image"].cuda(), val_data["label"].cuda()
                val_outputs = sliding_window_inference(val_inputs, (128, 128), 4, model)
                dice_metric(val_outputs, val_labels)
            metric = dice_metric.aggregate().item()
            print(f"Validation Dice: {metric:.4f}")

if __name__ == "__main__":
    train()
