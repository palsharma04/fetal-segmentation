# -*- coding: utf-8 -*-
"""Copy of MONAI_testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-VfqNfU8ixBdzttR_YlZCaDPEXhm8412

# Testing
"""

import glob
from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd, ScaleIntensityRanged, CropForegroundd, ToTensord
from monai.data import CacheDataset, DataLoader
from monai.transforms import ScaleIntensityd

# Step 1: Load test files
test_images = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/imagesTs/*.nii.gz"))
test_labels = sorted(glob.glob("/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/testing_plots/labelsTs/*.nii.gz"))
test_files = [{"image": img, "label": lbl} for img, lbl in zip(test_images, test_labels)]

target_size = [128, 128, 128]
# Step 2: Define transforms
test_transforms = Compose([
    LoadImaged(keys=["image", "label"]),
    EnsureChannelFirstd(keys=["image", "label"]),
    Spacingd(keys=["image", "label"], pixdim=(0.8, 0.8, 4.0), mode=("bilinear", "nearest")),
    SpatialPadd(keys=["image", "label"], spatial_size=target_size, method="symmetric"),
    Resized(keys=["image", "label"], spatial_size=target_size, mode=("trilinear", "nearest")),
    ScaleIntensityd(keys=["image"]),
    ToTensord(keys=["image", "label"]),
])

# Step 3: Create dataset and loader
test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_num=6, cache_rate=1.0, num_workers=4)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)

print(f"Test set ready: {len(test_loader)} samples")

import os
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric
from monai.transforms import AsDiscrete, Compose
from monai.networks.utils import one_hot

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Step 1: Load model
model = UNet(
    spatial_dims=3,
    in_channels=1,
    out_channels=6,
    channels=(32, 64, 128, 256, 512),
    strides=(2, 2, 2, 2),
    kernel_size=3,
    up_kernel_size=3,
    num_res_units=1,
    act='PRELU',
    norm='INSTANCE',
    dropout=0.5
).to(device)

data_dir = '/content/drive/My Drive/BEng/Year3/Research_Project/MONAI_training/mibirth-segmentation/'
model.load_state_dict(torch.load(os.path.join(data_dir, "best_metric_model.pth")))
model.eval()

# --- Step 2: DiceMetric
dice_metric = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)
# Re-create dice_metric fresh
dice_metric_case = DiceMetric(include_background=False, reduction="mean", get_not_nans=False)

# --- Step 3: Inference
all_preds = []
all_labels = []
case_dice_scores = []

num_classes = 6
roi_size = (128, 128, 128)

with torch.no_grad():
    for batch in tqdm(test_loader):
        test_images, test_labels = batch["image"].to(device), batch["label"].to(device)
        test_outputs = sliding_window_inference(test_images, roi_size=roi_size, sw_batch_size=1, predictor=model)

        test_outputs = torch.argmax(test_outputs, dim=1).unsqueeze(1)  # (B, 1, H, W, D)
        test_outputs = one_hot(test_outputs, num_classes=num_classes)

        if test_labels.ndim == 4:
            test_labels = test_labels.unsqueeze(1)
        test_labels = one_hot(test_labels, num_classes=num_classes)

        dice_metric_case.reset()
        dice_metric(y_pred=test_outputs, y=test_labels)
        dice_metric_case(y_pred=test_outputs, y=test_labels)
        case_dice = dice_metric_case.aggregate().item()

        case_dice_scores.append(case_dice)

        all_preds.append(test_outputs.cpu())
        all_labels.append(test_labels.cpu())

# --- Step 4: Calculate mean Dice
mean_dice = dice_metric.aggregate().item()
per_class_dice = dice_metric.aggregate(reduction=None).cpu().numpy()  # Get per-class Dice

print(f"Mean Dice on Test Set: {mean_dice:.4f}")
print("Dice per label (excluding background):")
for i, dice_val in enumerate(per_class_dice):
    print(f"Label {i+1}: {dice_val:.4f}")  # i+1 because label 0 is skipped

dice_metric.reset()

# --- Step 5: Volume Calculation
y_pred = torch.cat(all_preds, dim=0)
y = torch.cat(all_labels, dim=0)

spacing = [0.8, 0.8, 4.0]  # mm
voxel_volume_mm3 = np.prod(spacing)

labels = [0, 1, 2, 3, 4, 5]
volume_differences = []

for i in range(len(y_pred)):
    pred = y_pred[i].argmax(0).numpy()  # convert from one-hot
    gt = y[i].argmax(0).numpy()

    case_diff = {}
    for label in labels:
        pred_voxels = np.sum(pred == label)
        gt_voxels = np.sum(gt == label)

        pred_volume = pred_voxels * voxel_volume_mm3
        gt_volume = gt_voxels * voxel_volume_mm3
        volume_difference = pred_volume - gt_volume

        if gt_volume > 0:
            volume_error_percent = (volume_difference / gt_volume) * 100
        else:
            volume_error_percent = np.nan

        case_diff[f"Label_{label}_GT_volume_mm3"] = gt_volume
        case_diff[f"Label_{label}_Pred_volume_mm3"] = pred_volume
        case_diff[f"Label_{label}_Diff_volume_mm3"] = volume_difference
        case_diff[f"Label_{label}_Error_percent"] = volume_error_percent

    volume_differences.append(case_diff)

# --- Step 6: Dice, Precision, Recall, Volume Differences (cc and %)
case_ids = [os.path.basename(f["image"]) for f in test_ds.data]
combined_results = []

for i, case_id in enumerate(case_ids):
    row = {"Case": case_id}

    pred = y_pred[i].argmax(0).numpy()
    gt = y[i].argmax(0).numpy()

    def calc_metrics(pred_mask, gt_mask):
        tp = np.logical_and(pred_mask, gt_mask).sum()
        fp = np.logical_and(pred_mask, np.logical_not(gt_mask)).sum()
        fn = np.logical_and(np.logical_not(pred_mask), gt_mask).sum()

        dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 1.0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 1.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 1.0

        pred_vol_cc = pred_mask.sum() * voxel_volume_mm3 / 1000  # in cc
        gt_vol_cc = gt_mask.sum() * voxel_volume_mm3 / 1000
        abs_diff = pred_vol_cc - gt_vol_cc
        rel_diff = (abs_diff / gt_vol_cc) * 100 if gt_vol_cc > 0 else np.nan

        return round(dice, 4), round(precision, 4), round(recall, 4), round(abs_diff, 2), round(rel_diff, 2)

    label_groups = {
        "fetus": [1, 5],
        "placenta": [2],
        "umbilical_cord": [3],
        "amniotic_fluid": [4]
    }

    for name, indices in label_groups.items():
        pred_mask = np.isin(pred, indices)
        gt_mask = np.isin(gt, indices)

        dice, precision, recall, abs_vol_diff_cc, rel_vol_diff_pct = calc_metrics(pred_mask, gt_mask)

        row[f"{name}_dice"] = dice
        row[f"{name}_precision"] = precision
        row[f"{name}_recall"] = recall
        row[f"{name}_abs_vol_diff_cc"] = abs_vol_diff_cc
        row[f"{name}_rel_vol_diff_percent"] = rel_vol_diff_pct

    combined_results.append(row)

# --- Save full results to CSV
df_combined = pd.DataFrame(combined_results)
save_path = os.path.join(data_dir, "testing_plots", "3d-all_metrics_per_case.csv")
df_combined.to_csv(save_path, index=False)

print(f"All metrics saved to: {save_path}")
df_combined.head()

"""Visualising Test Sample"""

import matplotlib.pyplot as plt
import numpy as np

# Pick a test sample
sample_idx = 0  # change this to see different samples

# Load the sample
test_data = test_ds[sample_idx]
test_image = test_data["image"][0].numpy()  # (1, H, W, D) -> [H, W, D]
test_label = test_data["label"][0].numpy()  # (1, H, W, D)

# Predict
model.eval()
with torch.no_grad():
    input_tensor = test_data["image"].unsqueeze(0).to(device)  # Add batch dimension
    pred = sliding_window_inference(input_tensor, roi_size=(128,128,128), sw_batch_size=1, predictor=model)
    pred = torch.argmax(pred, dim=1).cpu().numpy()[0]  # (B, H, W, D) -> (H, W, D)

# Pick a slice to visualize
slice_idx = test_image.shape[2] // 2  # middle slice

fig, axs = plt.subplots(1, 3, figsize=(18, 6))

axs[0].imshow(test_image[:,:,slice_idx], cmap="gray")
axs[0].set_title("Input Image")

axs[1].imshow(test_label[:,:,slice_idx])
axs[1].set_title("Ground Truth Label")

axs[2].imshow(pred[:,:,slice_idx])
axs[2].set_title("Predicted Label")

plt.show()

case_num = 1
img_dim = 128
class_n = 6
qq=round(img_dim/2)
alpha_val = 0.6
with torch.no_grad():
    img_name = test_files[case_num]["image"]
    cur_case = test_ds[case_num]
    img = cur_case["image"]
    label = cur_case["label"]
    val_inputs = torch.unsqueeze(img, 1).cuda()
    val_labels = torch.unsqueeze(label, 1).cuda()
    val_outputs = sliding_window_inference(
        val_inputs, (img_dim, img_dim, img_dim), 4, model, overlap=0.8
    )
    plt.figure("check", (18, 18))
    plt.subplot(3, 3, 1)
    plt.title("Input image")
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, qq], cmap="gray")
    plt.subplot(3, 3, 2)
    plt.title("GT label")
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, qq], cmap="gray")
    plt.imshow(val_labels.cpu().numpy()[0, 0, :, :, qq], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")
    plt.subplot(3, 3, 3)
    plt.title("CNN output")
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, :, qq], cmap="gray")
    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, qq], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")

    plt.subplot(3, 3, 4)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, qq, :], cmap="gray")
    plt.subplot(3, 3, 5)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, qq, :], cmap="gray")
    plt.imshow(val_labels.cpu().numpy()[0, 0, :, qq, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")
    plt.subplot(3, 3, 6)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, :, qq, :], cmap="gray")
    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, qq, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")


    plt.subplot(3, 3, 7)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, qq, :, :], cmap="gray")
    plt.subplot(3, 3, 8)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, qq, :, :], cmap="gray")
    plt.imshow(val_labels.cpu().numpy()[0, 0, qq, :, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")
    plt.subplot(3, 3, 9)
    plt.imshow(val_inputs.cpu().numpy()[0, 0, qq, :, :], cmap="gray")
    plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, qq, :, :], alpha=alpha_val, vmin=0, vmax=class_n, cmap="jet")

    plt.show()
